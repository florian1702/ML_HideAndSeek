{
    "name": "root",
    "gauges": {
        "Seeker.Policy.Entropy.mean": {
            "value": 2.4353182315826416,
            "min": 2.422236442565918,
            "max": 2.4518232345581055,
            "count": 22
        },
        "Seeker.Policy.Entropy.sum": {
            "value": 227702.265625,
            "min": 124430.03125,
            "max": 5153159.0,
            "count": 22
        },
        "Seeker.Environment.SeekersMeanX.mean": {
            "value": 1.069430790366611,
            "min": 0.5589678804847014,
            "max": 1.3788032296657082,
            "count": 22
        },
        "Seeker.Environment.SeekersMeanX.sum": {
            "value": 249872.50416915864,
            "min": 132964.48457029834,
            "max": 4287669.962583492,
            "count": 22
        },
        "Seeker.Environment.SeekersMeanZ.mean": {
            "value": -1.3539436790406252,
            "min": -1.3617196305930837,
            "max": -0.8415387356650132,
            "count": 22
        },
        "Seeker.Environment.SeekersMeanZ.sum": {
            "value": -316348.94060784206,
            "min": -6339241.583611258,
            "max": -172904.3500945568,
            "count": 22
        },
        "Seeker.Environment.HidersMeanX.mean": {
            "value": 7.868086415233955,
            "min": 6.284929397803671,
            "max": 7.875194660119723,
            "count": 22
        },
        "Seeker.Environment.HidersMeanX.sum": {
            "value": 1838378.3909194134,
            "min": 798028.9102861211,
            "max": 37036735.58364081,
            "count": 22
        },
        "Seeker.Environment.HidersMeanZ.mean": {
            "value": -9.893350680569414,
            "min": -10.104681766141308,
            "max": -6.687636826719078,
            "count": 22
        },
        "Seeker.Environment.HidersMeanZ.sum": {
            "value": -2311581.3865150437,
            "min": -51417593.752767,
            "max": -849162.686072655,
            "count": 22
        },
        "Seeker.Environment.EpisodeLength.mean": {
            "value": 99.0,
            "min": 98.22695035460993,
            "max": 99.0,
            "count": 22
        },
        "Seeker.Environment.EpisodeLength.sum": {
            "value": 99000.0,
            "min": 39350.0,
            "max": 2077500.0,
            "count": 22
        },
        "Seeker.Environment.TimeHidden.mean": {
            "value": 0.4258866671025753,
            "min": 0.3872166679566726,
            "max": 0.47704000054299833,
            "count": 22
        },
        "Seeker.Environment.TimeHidden.sum": {
            "value": 212.94333355128765,
            "min": 77.44333359133452,
            "max": 4635.279999559745,
            "count": 22
        },
        "Seeker.Self-play.ELO.mean": {
            "value": 1660.9846925605668,
            "min": 1651.7499664490003,
            "max": 1686.265203693097,
            "count": 22
        },
        "Seeker.Self-play.ELO.sum": {
            "value": 1660984.6925605668,
            "min": 665024.8085048812,
            "max": 1749503.5996339608,
            "count": 22
        },
        "Seeker.Step.mean": {
            "value": 27499900.0,
            "min": 25399950.0,
            "max": 27499900.0,
            "count": 22
        },
        "Seeker.Step.sum": {
            "value": 27499900.0,
            "min": 25399950.0,
            "max": 27499900.0,
            "count": 22
        },
        "Seeker.Policy.ExtrinsicValueEstimate.mean": {
            "value": 57.250736236572266,
            "min": 48.69784164428711,
            "max": 60.96915054321289,
            "count": 22
        },
        "Seeker.Policy.ExtrinsicValueEstimate.sum": {
            "value": 57250.734375,
            "min": 18615.2890625,
            "max": 65480.8671875,
            "count": 22
        },
        "Seeker.Policy.CuriosityValueEstimate.mean": {
            "value": 0.6927444934844971,
            "min": 0.6246563196182251,
            "max": 0.708648145198822,
            "count": 22
        },
        "Seeker.Policy.CuriosityValueEstimate.sum": {
            "value": 692.7445068359375,
            "min": 253.696044921875,
            "max": 750.1195068359375,
            "count": 22
        },
        "Seeker.Environment.CumulativeReward.mean": {
            "value": 43.082,
            "min": 13.136,
            "max": 67.01675977653632,
            "count": 22
        },
        "Seeker.Environment.CumulativeReward.sum": {
            "value": 43082.0,
            "min": 13136.0,
            "max": 48350.0,
            "count": 22
        },
        "Seeker.Policy.ExtrinsicReward.mean": {
            "value": 43.082,
            "min": 13.136,
            "max": 67.01675977653632,
            "count": 22
        },
        "Seeker.Policy.ExtrinsicReward.sum": {
            "value": 43082.0,
            "min": 13136.0,
            "max": 48350.0,
            "count": 22
        },
        "Seeker.Policy.CuriosityReward.mean": {
            "value": 0.4591275060772896,
            "min": 0.0,
            "max": 0.4595381034165621,
            "count": 22
        },
        "Seeker.Policy.CuriosityReward.sum": {
            "value": 459.1275060772896,
            "min": 0.0,
            "max": 479.13842563703656,
            "count": 22
        },
        "Seeker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 22
        },
        "Seeker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 22
        },
        "Seeker.Losses.PolicyLoss.mean": {
            "value": 0.008798805732900898,
            "min": 0.006546842753111074,
            "max": 0.010059770291748767,
            "count": 20
        },
        "Seeker.Losses.PolicyLoss.sum": {
            "value": 0.008798805732900898,
            "min": 0.006546842753111074,
            "max": 0.010059770291748767,
            "count": 20
        },
        "Seeker.Losses.ValueLoss.mean": {
            "value": 1120.7819742838542,
            "min": 842.7769063313802,
            "max": 1120.7819742838542,
            "count": 20
        },
        "Seeker.Losses.ValueLoss.sum": {
            "value": 1120.7819742838542,
            "min": 842.7769063313802,
            "max": 1120.7819742838542,
            "count": 20
        },
        "Seeker.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 20
        },
        "Seeker.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 20
        },
        "Seeker.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 20
        },
        "Seeker.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 20
        },
        "Seeker.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 20
        },
        "Seeker.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 20
        },
        "Seeker.Losses.CuriosityForwardLoss.mean": {
            "value": 0.04688901044428349,
            "min": 0.04296665228903294,
            "max": 0.04760095278422038,
            "count": 20
        },
        "Seeker.Losses.CuriosityForwardLoss.sum": {
            "value": 0.04688901044428349,
            "min": 0.04296665228903294,
            "max": 0.04760095278422038,
            "count": 20
        },
        "Seeker.Losses.CuriosityInverseLoss.mean": {
            "value": 2.5800769170125326,
            "min": 2.548928960164388,
            "max": 2.7078997055689493,
            "count": 20
        },
        "Seeker.Losses.CuriosityInverseLoss.sum": {
            "value": 2.5800769170125326,
            "min": 2.548928960164388,
            "max": 2.7078997055689493,
            "count": 20
        },
        "Hider.Policy.Entropy.mean": {
            "value": 2.580786943435669,
            "min": 2.5660018920898438,
            "max": 2.588625907897949,
            "count": 20
        },
        "Hider.Policy.Entropy.sum": {
            "value": 269821.28125,
            "min": 242526.53125,
            "max": 5276655.0,
            "count": 20
        },
        "Hider.Environment.SeekersMeanX.mean": {
            "value": 0.6941146283729233,
            "min": 0.512983431193679,
            "max": 1.1121636755182656,
            "count": 20
        },
        "Hider.Environment.SeekersMeanX.sum": {
            "value": 181424.21099097282,
            "min": 120961.49307546951,
            "max": 4617723.83709054,
            "count": 20
        },
        "Hider.Environment.SeekersMeanZ.mean": {
            "value": -1.1227914639498302,
            "min": -1.375444052152588,
            "max": -0.9024391014613464,
            "count": 20
        },
        "Hider.Environment.SeekersMeanZ.sum": {
            "value": -293469.6188898869,
            "min": -6033734.601065851,
            "max": -212795.14012458548,
            "count": 20
        },
        "Hider.Environment.HidersMeanX.mean": {
            "value": 6.722593256170444,
            "min": 6.485973675559029,
            "max": 7.700470508908761,
            "count": 20
        },
        "Hider.Environment.HidersMeanX.sum": {
            "value": 1757117.8123315498,
            "min": 1602419.8760463428,
            "max": 38722367.69098193,
            "count": 20
        },
        "Hider.Environment.HidersMeanZ.mean": {
            "value": -9.709355741619722,
            "min": -10.021726029699618,
            "max": -9.667701302407194,
            "count": 20
        },
        "Hider.Environment.HidersMeanZ.sum": {
            "value": -2537782.8569658548,
            "min": -50075791.68052982,
            "max": -2279643.9671076164,
            "count": 20
        },
        "Hider.Environment.EpisodeLength.mean": {
            "value": 99.0,
            "min": 98.54926108374384,
            "max": 99.0,
            "count": 20
        },
        "Hider.Environment.EpisodeLength.sum": {
            "value": 99000.0,
            "min": 99000.0,
            "max": 2000550.0,
            "count": 20
        },
        "Hider.Environment.TimeHidden.mean": {
            "value": 0.4339466665573418,
            "min": 0.4149133334197104,
            "max": 0.46705999873206017,
            "count": 20
        },
        "Hider.Environment.TimeHidden.sum": {
            "value": 216.9733332786709,
            "min": 207.4566667098552,
            "max": 4475.70000067167,
            "count": 20
        },
        "Hider.Self-play.ELO.mean": {
            "value": 1413.969703686194,
            "min": 1397.390992184706,
            "max": 1438.872000863869,
            "count": 20
        },
        "Hider.Self-play.ELO.sum": {
            "value": 1413969.703686194,
            "min": 359718.00021596724,
            "max": 1435474.1476920927,
            "count": 20
        },
        "Hider.Step.mean": {
            "value": 29599900.0,
            "min": 27699948.0,
            "max": 29599900.0,
            "count": 20
        },
        "Hider.Step.sum": {
            "value": 29599900.0,
            "min": 27699948.0,
            "max": 29599900.0,
            "count": 20
        },
        "Hider.Policy.ExtrinsicValueEstimate.mean": {
            "value": -54.19585037231445,
            "min": -56.0880012512207,
            "max": -33.13446044921875,
            "count": 20
        },
        "Hider.Policy.ExtrinsicValueEstimate.sum": {
            "value": -54195.8515625,
            "min": -56088.0,
            "max": -6693.16064453125,
            "count": 20
        },
        "Hider.Policy.CuriosityValueEstimate.mean": {
            "value": 1.0173088312149048,
            "min": 0.9432808756828308,
            "max": 1.2023106813430786,
            "count": 20
        },
        "Hider.Policy.CuriosityValueEstimate.sum": {
            "value": 1017.308837890625,
            "min": 242.86676025390625,
            "max": 1071.721923828125,
            "count": 20
        },
        "Hider.Environment.CumulativeReward.mean": {
            "value": -43.594,
            "min": -71.23762376237623,
            "max": -22.352,
            "count": 20
        },
        "Hider.Environment.CumulativeReward.sum": {
            "value": -43594.0,
            "min": -52176.0,
            "max": -14390.0,
            "count": 20
        },
        "Hider.Policy.ExtrinsicReward.mean": {
            "value": -43.594,
            "min": -71.23762376237623,
            "max": -22.352,
            "count": 20
        },
        "Hider.Policy.ExtrinsicReward.sum": {
            "value": -43594.0,
            "min": -52176.0,
            "max": -14390.0,
            "count": 20
        },
        "Hider.Policy.CuriosityReward.mean": {
            "value": 0.8319078916311264,
            "min": 0.0,
            "max": 0.8741431035995484,
            "count": 20
        },
        "Hider.Policy.CuriosityReward.sum": {
            "value": 831.9078916311264,
            "min": 0.0,
            "max": 874.1431035995483,
            "count": 20
        },
        "Hider.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        },
        "Hider.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 20
        },
        "Hider.Losses.PolicyLoss.mean": {
            "value": 0.008409258454533605,
            "min": 0.0069351566058079095,
            "max": 0.010624980573326562,
            "count": 18
        },
        "Hider.Losses.PolicyLoss.sum": {
            "value": 0.008409258454533605,
            "min": 0.0069351566058079095,
            "max": 0.010624980573326562,
            "count": 18
        },
        "Hider.Losses.ValueLoss.mean": {
            "value": 835.1610616048177,
            "min": 835.1610616048177,
            "max": 963.9985148111979,
            "count": 18
        },
        "Hider.Losses.ValueLoss.sum": {
            "value": 835.1610616048177,
            "min": 835.1610616048177,
            "max": 963.9985148111979,
            "count": 18
        },
        "Hider.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 18
        },
        "Hider.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 18
        },
        "Hider.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 18
        },
        "Hider.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 18
        },
        "Hider.Policy.Beta.mean": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 18
        },
        "Hider.Policy.Beta.sum": {
            "value": 0.005000000000000001,
            "min": 0.005000000000000001,
            "max": 0.005000000000000001,
            "count": 18
        },
        "Hider.Losses.CuriosityForwardLoss.mean": {
            "value": 0.08234615872303645,
            "min": 0.08121530388792356,
            "max": 0.09759493172168732,
            "count": 18
        },
        "Hider.Losses.CuriosityForwardLoss.sum": {
            "value": 0.08234615872303645,
            "min": 0.08121530388792356,
            "max": 0.09759493172168732,
            "count": 18
        },
        "Hider.Losses.CuriosityInverseLoss.mean": {
            "value": 2.8328208605448406,
            "min": 2.8127085606257123,
            "max": 3.360315283139547,
            "count": 18
        },
        "Hider.Losses.CuriosityInverseLoss.sum": {
            "value": 2.8328208605448406,
            "min": 2.8127085606257123,
            "max": 3.360315283139547,
            "count": 18
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1735828684",
        "python_version": "3.10.12 (main, Oct 23 2024, 17:55:59) [MSC v.1941 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Projects\\ML_HideAndSeek\\venv\\Scripts\\mlagents-learn TrainerConfig/HiderVsSeekerPPO.yaml --num-areas=25 --num-envs=5 --env=20ArenasBuild/ML_HideAndSeek.exe --resume --time-scale=1 --no-graphics --run-id=BuildTraining/VersusPPO/Training2",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.1+cu124",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1735832921"
    },
    "total": 4237.46133890003,
    "count": 1,
    "self": 0.015354900038801134,
    "children": {
        "run_training.setup": {
            "total": 0.35990189999574795,
            "count": 1,
            "self": 0.35990189999574795
        },
        "TrainerController.start_learning": {
            "total": 4237.086082099995,
            "count": 1,
            "self": 1.3221861939528026,
            "children": {
                "TrainerController._reset_env": {
                    "total": 15.681344600045122,
                    "count": 4,
                    "self": 15.681344600045122
                },
                "TrainerController.advance": {
                    "total": 4219.377712105983,
                    "count": 47075,
                    "self": 1.7647210917202756,
                    "children": {
                        "env_step": {
                            "total": 1985.0743482875987,
                            "count": 47075,
                            "self": 704.9065583777265,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 1279.3020155019476,
                                    "count": 85480,
                                    "self": 18.14364819403272,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 1261.158367307915,
                                            "count": 169278,
                                            "self": 1261.158367307915
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 0.8657744079246186,
                                    "count": 47075,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 21031.46676300274,
                                            "count": 85466,
                                            "is_parallel": true,
                                            "self": 16379.256003598508,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.17639700003201142,
                                                    "count": 32,
                                                    "is_parallel": true,
                                                    "self": 0.008337299979757518,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.1680597000522539,
                                                            "count": 192,
                                                            "is_parallel": true,
                                                            "self": 0.1680597000522539
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 4652.0343624042,
                                                    "count": 85466,
                                                    "is_parallel": true,
                                                    "self": 587.43593649799,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 102.72844760929001,
                                                            "count": 85466,
                                                            "is_parallel": true,
                                                            "self": 102.72844760929001
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 3030.895987301541,
                                                            "count": 85466,
                                                            "is_parallel": true,
                                                            "self": 3030.895987301541
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 930.9739909953787,
                                                            "count": 170932,
                                                            "is_parallel": true,
                                                            "self": 48.43948379973881,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 882.5345071956399,
                                                                    "count": 1025592,
                                                                    "is_parallel": true,
                                                                    "self": 882.5345071956399
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 2232.538642726664,
                            "count": 94149,
                            "self": 19.062279711244628,
                            "children": {
                                "process_trajectory": {
                                    "total": 952.2440812154091,
                                    "count": 94149,
                                    "self": 951.784872115415,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 0.459209099994041,
                                            "count": 1,
                                            "self": 0.459209099994041
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 1261.2322818000102,
                                    "count": 40,
                                    "self": 1018.061058100313,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 243.1712236996973,
                                            "count": 1180,
                                            "self": 243.1712236996973
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 2.400018274784088e-06,
                    "count": 1,
                    "self": 2.400018274784088e-06
                },
                "TrainerController._save_models": {
                    "total": 0.7048367999959737,
                    "count": 1,
                    "self": 0.02687510004034266,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.677961699955631,
                            "count": 2,
                            "self": 0.677961699955631
                        }
                    }
                }
            }
        }
    }
}