{
    "name": "root",
    "gauges": {
        "Seeker.Policy.Entropy.mean": {
            "value": 3.6671881675720215,
            "min": 3.650684118270874,
            "max": 3.6728367805480957,
            "count": 89
        },
        "Seeker.Policy.Entropy.sum": {
            "value": 366718.8125,
            "min": 153601.265625,
            "max": 7709840.5,
            "count": 89
        },
        "Seeker.Environment.SeekersMeanX.mean": {
            "value": -0.7767194139666371,
            "min": -1.0344763871151657,
            "max": -0.5165718857186065,
            "count": 89
        },
        "Seeker.Environment.SeekersMeanX.sum": {
            "value": -194179.85349165928,
            "min": -4013552.2189592845,
            "max": -108318.110432446,
            "count": 89
        },
        "Seeker.Environment.SeekersMeanZ.mean": {
            "value": -0.10345275763709844,
            "min": -0.5215944358831793,
            "max": 0.14203409277826548,
            "count": 89
        },
        "Seeker.Environment.SeekersMeanZ.sum": {
            "value": -25863.189409274608,
            "min": -1039806.8227912784,
            "max": 35508.52319456637,
            "count": 89
        },
        "Seeker.Environment.HidersMeanX.mean": {
            "value": 5.769637976050675,
            "min": 5.374740357836694,
            "max": 5.893635421279624,
            "count": 89
        },
        "Seeker.Environment.HidersMeanX.sum": {
            "value": 1442409.4940126687,
            "min": 593836.5330637619,
            "max": 30098760.1415852,
            "count": 89
        },
        "Seeker.Environment.HidersMeanZ.mean": {
            "value": -6.496723950370103,
            "min": -6.720625451134503,
            "max": -6.08640579202386,
            "count": 89
        },
        "Seeker.Environment.HidersMeanZ.sum": {
            "value": -1624180.9875925258,
            "min": -34269323.90814661,
            "max": -639224.7683073059,
            "count": 89
        },
        "Seeker.Environment.EpisodeLength.mean": {
            "value": 99.0,
            "min": 99.0,
            "max": 99.0,
            "count": 89
        },
        "Seeker.Environment.EpisodeLength.sum": {
            "value": 99000.0,
            "min": 41580.0,
            "max": 2079990.0,
            "count": 89
        },
        "Seeker.Environment.TimeHidden.mean": {
            "value": 0.5087466669455171,
            "min": 0.4705733337067068,
            "max": 0.5243266673833131,
            "count": 89
        },
        "Seeker.Environment.TimeHidden.sum": {
            "value": 254.37333347275853,
            "min": 106.07999989576638,
            "max": 5297.01333626546,
            "count": 89
        },
        "Seeker.Environment.LockedBoxes.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 89
        },
        "Seeker.Environment.LockedBoxes.sum": {
            "value": 638.0,
            "min": 274.0,
            "max": 13224.0,
            "count": 89
        },
        "Seeker.Self-play.ELO.mean": {
            "value": 1513.5722428543313,
            "min": 1476.9311011098814,
            "max": 1532.3638871021208,
            "count": 89
        },
        "Seeker.Self-play.ELO.sum": {
            "value": 1513572.2428543314,
            "min": 630165.43599737,
            "max": 1532363.8871021208,
            "count": 89
        },
        "Seeker.Step.mean": {
            "value": 87499900.0,
            "min": 78699900.0,
            "max": 87499900.0,
            "count": 89
        },
        "Seeker.Step.sum": {
            "value": 87499900.0,
            "min": 78699900.0,
            "max": 87499900.0,
            "count": 89
        },
        "Seeker.Policy.ExtrinsicValueEstimate.mean": {
            "value": 23.509933471679688,
            "min": 18.28157615661621,
            "max": 29.003211975097656,
            "count": 89
        },
        "Seeker.Policy.ExtrinsicValueEstimate.sum": {
            "value": 23509.93359375,
            "min": 8784.783203125,
            "max": 29003.212890625,
            "count": 89
        },
        "Seeker.Policy.CuriosityValueEstimate.mean": {
            "value": 0.21387483179569244,
            "min": 0.15371745824813843,
            "max": 0.2750057578086853,
            "count": 89
        },
        "Seeker.Policy.CuriosityValueEstimate.sum": {
            "value": 213.8748321533203,
            "min": 78.11119079589844,
            "max": 275.0057678222656,
            "count": 89
        },
        "Seeker.Environment.CumulativeReward.mean": {
            "value": -4.922,
            "min": -15.662,
            "max": 18.338,
            "count": 89
        },
        "Seeker.Environment.CumulativeReward.sum": {
            "value": -4922.0,
            "min": -15662.0,
            "max": 18338.0,
            "count": 89
        },
        "Seeker.Policy.ExtrinsicReward.mean": {
            "value": -4.922,
            "min": -15.662,
            "max": 18.338,
            "count": 89
        },
        "Seeker.Policy.ExtrinsicReward.sum": {
            "value": -4922.0,
            "min": -15662.0,
            "max": 18338.0,
            "count": 89
        },
        "Seeker.Policy.CuriosityReward.mean": {
            "value": 0.1685491077899933,
            "min": 0.0,
            "max": 0.17051531793177127,
            "count": 89
        },
        "Seeker.Policy.CuriosityReward.sum": {
            "value": 168.5491077899933,
            "min": 0.0,
            "max": 170.51531793177128,
            "count": 89
        },
        "Seeker.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 89
        },
        "Seeker.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 89
        },
        "Seeker.Losses.PolicyLoss.mean": {
            "value": 0.015954135540111263,
            "min": 0.013644428682164289,
            "max": 0.0170273141314586,
            "count": 87
        },
        "Seeker.Losses.PolicyLoss.sum": {
            "value": 0.015954135540111263,
            "min": 0.013644428682164289,
            "max": 0.0170273141314586,
            "count": 87
        },
        "Seeker.Losses.ValueLoss.mean": {
            "value": 1015.332344563802,
            "min": 949.2749064127604,
            "max": 1126.264021809896,
            "count": 87
        },
        "Seeker.Losses.ValueLoss.sum": {
            "value": 1015.332344563802,
            "min": 949.2749064127604,
            "max": 1126.264021809896,
            "count": 87
        },
        "Seeker.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 87
        },
        "Seeker.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 87
        },
        "Seeker.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 87
        },
        "Seeker.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 87
        },
        "Seeker.Policy.Beta.mean": {
            "value": 0.010000000000000002,
            "min": 0.010000000000000002,
            "max": 0.010000000000000002,
            "count": 87
        },
        "Seeker.Policy.Beta.sum": {
            "value": 0.010000000000000002,
            "min": 0.010000000000000002,
            "max": 0.010000000000000002,
            "count": 87
        },
        "Seeker.Losses.CuriosityForwardLoss.mean": {
            "value": 0.3339062521855036,
            "min": 0.2887681216001511,
            "max": 0.3400511473417282,
            "count": 87
        },
        "Seeker.Losses.CuriosityForwardLoss.sum": {
            "value": 0.3339062521855036,
            "min": 0.2887681216001511,
            "max": 0.3400511473417282,
            "count": 87
        },
        "Seeker.Losses.CuriosityInverseLoss.mean": {
            "value": 25.786438496907554,
            "min": 21.72330576578776,
            "max": 26.08660144805908,
            "count": 87
        },
        "Seeker.Losses.CuriosityInverseLoss.sum": {
            "value": 25.786438496907554,
            "min": 21.72330576578776,
            "max": 26.08660144805908,
            "count": 87
        },
        "Hider.Policy.Entropy.mean": {
            "value": 3.744072198867798,
            "min": 3.6808338165283203,
            "max": 3.745051860809326,
            "count": 80
        },
        "Hider.Policy.Entropy.sum": {
            "value": 374407.21875,
            "min": 368083.375,
            "max": 7840184.0,
            "count": 80
        },
        "Hider.Environment.SeekersMeanX.mean": {
            "value": -0.6231192385208011,
            "min": -1.055546824558556,
            "max": -0.48045695515561476,
            "count": 80
        },
        "Hider.Environment.SeekersMeanX.sum": {
            "value": -155779.80963020027,
            "min": -3977285.7910792045,
            "max": -120114.23878890369,
            "count": 80
        },
        "Hider.Environment.SeekersMeanZ.mean": {
            "value": -0.06585880949918926,
            "min": -0.48396166751012204,
            "max": 0.3212020468154699,
            "count": 80
        },
        "Hider.Environment.SeekersMeanZ.sum": {
            "value": -16464.702374797314,
            "min": -1159948.213714826,
            "max": 80300.51170386747,
            "count": 80
        },
        "Hider.Environment.HidersMeanX.mean": {
            "value": 5.6270423038545845,
            "min": 5.4155515621067885,
            "max": 5.873433065366715,
            "count": 80
        },
        "Hider.Environment.HidersMeanX.sum": {
            "value": 1406760.5759636462,
            "min": 1353887.890526697,
            "max": 29765939.159647066,
            "count": 80
        },
        "Hider.Environment.HidersMeanZ.mean": {
            "value": -6.556641185023099,
            "min": -6.725647739729583,
            "max": -6.181299527821362,
            "count": 80
        },
        "Hider.Environment.HidersMeanZ.sum": {
            "value": -1639160.2962557748,
            "min": -34333622.080330275,
            "max": -1545324.8819553405,
            "count": 80
        },
        "Hider.Environment.EpisodeLength.mean": {
            "value": 99.0,
            "min": 99.0,
            "max": 99.0,
            "count": 80
        },
        "Hider.Environment.EpisodeLength.sum": {
            "value": 99000.0,
            "min": 99000.0,
            "max": 2079990.0,
            "count": 80
        },
        "Hider.Environment.TimeHidden.mean": {
            "value": 0.5012400001008064,
            "min": 0.469513332426548,
            "max": 0.5459066666252911,
            "count": 80
        },
        "Hider.Environment.TimeHidden.sum": {
            "value": 250.62000005040318,
            "min": 234.756666213274,
            "max": 5293.966672566254,
            "count": 80
        },
        "Hider.Environment.LockedBoxes.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 80
        },
        "Hider.Environment.LockedBoxes.sum": {
            "value": 631.0,
            "min": 581.0,
            "max": 13065.0,
            "count": 80
        },
        "Hider.Self-play.ELO.mean": {
            "value": 1331.7187939308212,
            "min": 1320.8820058097858,
            "max": 1357.7087783257307,
            "count": 80
        },
        "Hider.Self-play.ELO.sum": {
            "value": 1331718.7939308211,
            "min": 331014.6463777582,
            "max": 1357708.7783257307,
            "count": 80
        },
        "Hider.Step.mean": {
            "value": 96299900.0,
            "min": 88399900.0,
            "max": 96299900.0,
            "count": 80
        },
        "Hider.Step.sum": {
            "value": 96299900.0,
            "min": 88399900.0,
            "max": 96299900.0,
            "count": 80
        },
        "Hider.Policy.ExtrinsicValueEstimate.mean": {
            "value": -22.167766571044922,
            "min": -31.17190933227539,
            "max": -12.338140487670898,
            "count": 80
        },
        "Hider.Policy.ExtrinsicValueEstimate.sum": {
            "value": -22167.765625,
            "min": -31171.91015625,
            "max": -6298.35595703125,
            "count": 80
        },
        "Hider.Policy.CuriosityValueEstimate.mean": {
            "value": 0.48537737131118774,
            "min": 0.34637024998664856,
            "max": 0.48748779296875,
            "count": 80
        },
        "Hider.Policy.CuriosityValueEstimate.sum": {
            "value": 485.37738037109375,
            "min": 91.8695068359375,
            "max": 487.48779296875,
            "count": 80
        },
        "Hider.Environment.CumulativeReward.mean": {
            "value": 1.236,
            "min": -17.788,
            "max": 28.468,
            "count": 80
        },
        "Hider.Environment.CumulativeReward.sum": {
            "value": 1236.0,
            "min": -17788.0,
            "max": 28468.0,
            "count": 80
        },
        "Hider.Policy.ExtrinsicReward.mean": {
            "value": 1.236,
            "min": -17.788,
            "max": 28.468,
            "count": 80
        },
        "Hider.Policy.ExtrinsicReward.sum": {
            "value": 1236.0,
            "min": -17788.0,
            "max": 28468.0,
            "count": 80
        },
        "Hider.Policy.CuriosityReward.mean": {
            "value": 0.42562222120165827,
            "min": 0.0,
            "max": 0.4354350780546665,
            "count": 80
        },
        "Hider.Policy.CuriosityReward.sum": {
            "value": 425.62222120165825,
            "min": 0.0,
            "max": 435.4350780546665,
            "count": 80
        },
        "Hider.IsTraining.mean": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 80
        },
        "Hider.IsTraining.sum": {
            "value": 1.0,
            "min": 1.0,
            "max": 1.0,
            "count": 80
        },
        "Hider.Losses.PolicyLoss.mean": {
            "value": 0.018804944527801126,
            "min": 0.016648833286793282,
            "max": 0.02092953698399166,
            "count": 78
        },
        "Hider.Losses.PolicyLoss.sum": {
            "value": 0.018804944527801126,
            "min": 0.016648833286793282,
            "max": 0.02092953698399166,
            "count": 78
        },
        "Hider.Losses.ValueLoss.mean": {
            "value": 1149.130948893229,
            "min": 1099.2368530273438,
            "max": 1252.2285278320312,
            "count": 78
        },
        "Hider.Losses.ValueLoss.sum": {
            "value": 1149.130948893229,
            "min": 1099.2368530273438,
            "max": 1252.2285278320312,
            "count": 78
        },
        "Hider.Policy.LearningRate.mean": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 78
        },
        "Hider.Policy.LearningRate.sum": {
            "value": 0.0003,
            "min": 0.0003,
            "max": 0.0003,
            "count": 78
        },
        "Hider.Policy.Epsilon.mean": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 78
        },
        "Hider.Policy.Epsilon.sum": {
            "value": 0.20000000000000007,
            "min": 0.20000000000000007,
            "max": 0.20000000000000007,
            "count": 78
        },
        "Hider.Policy.Beta.mean": {
            "value": 0.010000000000000002,
            "min": 0.010000000000000002,
            "max": 0.010000000000000002,
            "count": 78
        },
        "Hider.Policy.Beta.sum": {
            "value": 0.010000000000000002,
            "min": 0.010000000000000002,
            "max": 0.010000000000000002,
            "count": 78
        },
        "Hider.Losses.CuriosityForwardLoss.mean": {
            "value": 0.8475412786006927,
            "min": 0.6817474464575449,
            "max": 0.851264609893163,
            "count": 78
        },
        "Hider.Losses.CuriosityForwardLoss.sum": {
            "value": 0.8475412786006927,
            "min": 0.6817474464575449,
            "max": 0.851264609893163,
            "count": 78
        },
        "Hider.Losses.CuriosityInverseLoss.mean": {
            "value": 55.24614219665527,
            "min": 45.7848258972168,
            "max": 55.29665184020996,
            "count": 78
        },
        "Hider.Losses.CuriosityInverseLoss.sum": {
            "value": 55.24614219665527,
            "min": 45.7848258972168,
            "max": 55.29665184020996,
            "count": 78
        }
    },
    "metadata": {
        "timer_format_version": "0.1.0",
        "start_time_seconds": "1739174236",
        "python_version": "3.10.12 (main, Oct 23 2024, 17:55:59) [MSC v.1941 64 bit (AMD64)]",
        "command_line_arguments": "D:\\Projects\\ML_HideAndSeek\\venv\\Scripts\\mlagents-learn TrainerConfig/HiderVsSeekerPPO.yaml --num-areas=5 --num-envs=2 --env=Builds/PPO/ML_HideAndSeek.exe --time-scale=1 --no-graphics --run-id=BuildTraining/PPO/5120_100000 --resume",
        "mlagents_version": "1.1.0",
        "mlagents_envs_version": "1.1.0",
        "communication_protocol_version": "1.5.0",
        "pytorch_version": "2.5.1+cu124",
        "numpy_version": "1.23.5",
        "end_time_seconds": "1739221137"
    },
    "total": 46899.7863026,
    "count": 1,
    "self": 3.432109700021101,
    "children": {
        "run_training.setup": {
            "total": 0.18362369999522343,
            "count": 1,
            "self": 0.18362369999522343
        },
        "TrainerController.start_learning": {
            "total": 46896.17056919998,
            "count": 1,
            "self": 36.97519891036791,
            "children": {
                "TrainerController._reset_env": {
                    "total": 15.612110900023254,
                    "count": 10,
                    "self": 15.612110900023254
                },
                "TrainerController.advance": {
                    "total": 46842.62084918958,
                    "count": 1710255,
                    "self": 44.4289685873955,
                    "children": {
                        "env_step": {
                            "total": 32899.98209320192,
                            "count": 1710255,
                            "self": 3902.992385728139,
                            "children": {
                                "SubprocessEnvManager._take_step": {
                                    "total": 28977.086309798236,
                                    "count": 1710269,
                                    "self": 204.58896537596593,
                                    "children": {
                                        "TorchPolicy.evaluate": {
                                            "total": 28772.49734442227,
                                            "count": 3386706,
                                            "self": 28772.49734442227
                                        }
                                    }
                                },
                                "workers": {
                                    "total": 19.90339767554542,
                                    "count": 1710254,
                                    "self": 0.0,
                                    "children": {
                                        "worker_root": {
                                            "total": 93676.40376510198,
                                            "count": 1710258,
                                            "is_parallel": true,
                                            "self": 67726.69527530912,
                                            "children": {
                                                "steps_from_proto": {
                                                    "total": 0.047551399999065325,
                                                    "count": 38,
                                                    "is_parallel": true,
                                                    "self": 0.006716500676702708,
                                                    "children": {
                                                        "_process_rank_one_or_two_observation": {
                                                            "total": 0.04083489932236262,
                                                            "count": 456,
                                                            "is_parallel": true,
                                                            "self": 0.04083489932236262
                                                        }
                                                    }
                                                },
                                                "UnityEnvironment.step": {
                                                    "total": 25949.66093839286,
                                                    "count": 1710258,
                                                    "is_parallel": true,
                                                    "self": 2898.238931969361,
                                                    "children": {
                                                        "UnityEnvironment._generate_step_input": {
                                                            "total": 425.67833461621194,
                                                            "count": 1710258,
                                                            "is_parallel": true,
                                                            "self": 425.67833461621194
                                                        },
                                                        "communicator.exchange": {
                                                            "total": 17188.556795490207,
                                                            "count": 1710258,
                                                            "is_parallel": true,
                                                            "self": 17188.556795490207
                                                        },
                                                        "steps_from_proto": {
                                                            "total": 5437.186876317079,
                                                            "count": 3420516,
                                                            "is_parallel": true,
                                                            "self": 785.1161930617236,
                                                            "children": {
                                                                "_process_rank_one_or_two_observation": {
                                                                    "total": 4652.070683255355,
                                                                    "count": 41046192,
                                                                    "is_parallel": true,
                                                                    "self": 4652.070683255355
                                                                }
                                                            }
                                                        }
                                                    }
                                                }
                                            }
                                        }
                                    }
                                }
                            }
                        },
                        "trainer_advance": {
                            "total": 13898.209787400265,
                            "count": 3420508,
                            "self": 260.4754214990535,
                            "children": {
                                "process_trajectory": {
                                    "total": 5823.341585401067,
                                    "count": 3420508,
                                    "self": 5820.066179501067,
                                    "children": {
                                        "RLTrainer._checkpoint": {
                                            "total": 3.275405899999896,
                                            "count": 7,
                                            "self": 3.275405899999896
                                        }
                                    }
                                },
                                "_update_policy": {
                                    "total": 7814.392780500144,
                                    "count": 167,
                                    "self": 6375.54522220057,
                                    "children": {
                                        "TorchPPOOptimizer.update": {
                                            "total": 1438.8475582995743,
                                            "count": 5010,
                                            "self": 1438.8475582995743
                                        }
                                    }
                                }
                            }
                        }
                    }
                },
                "trainer_threads": {
                    "total": 1.00000761449337e-06,
                    "count": 1,
                    "self": 1.00000761449337e-06
                },
                "TrainerController._save_models": {
                    "total": 0.9624092000012752,
                    "count": 1,
                    "self": 0.029725900007179007,
                    "children": {
                        "RLTrainer._checkpoint": {
                            "total": 0.9326832999940962,
                            "count": 2,
                            "self": 0.9326832999940962
                        }
                    }
                }
            }
        }
    }
}